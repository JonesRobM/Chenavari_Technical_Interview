{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c331440",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pytesseract\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install pytesseract\n",
    "    import pytesseract\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install pillow\n",
    "    from PIL import Image\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    import re\n",
    "except ImportError:\n",
    "    raise ImportError(\"The 're' module is part of the Python standard library and should always be available.\")\n",
    "\n",
    "try:\n",
    "    from datetime import datetime\n",
    "except ImportError:\n",
    "    raise ImportError(\"The 'datetime' module is part of the Python standard library and should always be available.\")\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d09ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8568d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRProcessor:\n",
    "    \"\"\"OCR processing with emphasis on preprocessing quality over engine selection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.confidence_threshold = 70  # Minimum confidence for acceptance\n",
    "        \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Critical preprocessing pipeline based on practitioner consensus\n",
    "        Priority: CLAHE -> Adaptive threshold -> Noise reduction -> ROI\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing {image_path}\")\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 1. CLAHE for contrast enhancement (most important step)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "        \n",
    "        # 2. Adaptive thresholding (better than global for financial tables)\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            enhanced, 255, cv2.THRESH_BINARY, cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "        \n",
    "        # 3. Noise reduction via median filtering\n",
    "        denoised = cv2.medianBlur(thresh, 3)\n",
    "        \n",
    "        # 4. Morphological operations to clean up table structure\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        cleaned = cv2.morphologyEx(denoised, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def extract_text_with_confidence(self, processed_img):\n",
    "        \"\"\"Extract text with confidence scores for validation\"\"\"\n",
    "        \n",
    "        # Get detailed OCR data including confidence\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789./- ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        # Extract text with confidence\n",
    "        ocr_data = pytesseract.image_to_data(\n",
    "            processed_img, \n",
    "            output_type=pytesseract.Output.DICT,\n",
    "            config=custom_config\n",
    "        )\n",
    "        \n",
    "        return ocr_data\n",
    "    \n",
    "    def validate_financial_number(self, text):\n",
    "        \"\"\"Business logic validation for financial numbers\"\"\"\n",
    "        # Pattern for financial numbers: optional parentheses, digits, commas, decimal\n",
    "        pattern = r'^[\\(]?[\\d,]+\\.?\\d*[\\)]?$'\n",
    "        \n",
    "        if re.match(pattern, text.strip()):\n",
    "            # Clean and convert\n",
    "            cleaned = text.replace(',', '').replace('(', '-').replace(')', '')\n",
    "            try:\n",
    "                return float(cleaned)\n",
    "            except ValueError:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def extract_data_from_image(self, image_path):\n",
    "        \"\"\"Main extraction method with comprehensive validation\"\"\"\n",
    "        \n",
    "        processed_img = self.preprocess_image(image_path)\n",
    "        ocr_data = self.extract_text_with_confidence(processed_img)\n",
    "        \n",
    "        # Extract high-confidence text\n",
    "        extracted_data = []\n",
    "        for i, confidence in enumerate(ocr_data['conf']):\n",
    "            if int(confidence) > self.confidence_threshold:\n",
    "                text = ocr_data['text'][i].strip()\n",
    "                if text:\n",
    "                    extracted_data.append({\n",
    "                        'text': text,\n",
    "                        'confidence': confidence,\n",
    "                        'x': ocr_data['left'][i],\n",
    "                        'y': ocr_data['top'][i]\n",
    "                    })\n",
    "        \n",
    "        logger.info(f\"Extracted {len(extracted_data)} high-confidence text elements\")\n",
    "        return extracted_data, processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf7d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParser:\n",
    "    \"\"\"Parse OCR results into structured financial data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.date_patterns = [\n",
    "            r'\\d{2}/\\d{2}/\\d{2}',  # MM/DD/YY\n",
    "            r'\\d{2}/\\d{2}/\\d{4}',  # MM/DD/YYYY\n",
    "        ]\n",
    "    \n",
    "    def parse_date(self, text):\n",
    "        \"\"\"Parse various date formats\"\"\"\n",
    "        for pattern in self.date_patterns:\n",
    "            if re.match(pattern, text):\n",
    "                try:\n",
    "                    # Try MM/DD/YY format first (common in financial data)\n",
    "                    if len(text.split('/')[2]) == 2:\n",
    "                        date_obj = datetime.strptime(text, '%m/%d/%y')\n",
    "                    else:\n",
    "                        date_obj = datetime.strptime(text, '%m/%d/%Y')\n",
    "                    return date_obj.strftime('%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def extract_table_data(self, extracted_data, data_type=\"bond\"):\n",
    "        \"\"\"Extract structured data from OCR results\"\"\"\n",
    "        \n",
    "        # Sort by vertical position to process row by row\n",
    "        sorted_data = sorted(extracted_data, key=lambda x: (x['y'], x['x']))\n",
    "        \n",
    "        parsed_rows = []\n",
    "        current_row = []\n",
    "        current_y = None\n",
    "        y_tolerance = 5  # Pixels tolerance for same row\n",
    "        \n",
    "        for item in sorted_data:\n",
    "            if current_y is None or abs(item['y'] - current_y) <= y_tolerance:\n",
    "                current_row.append(item)\n",
    "                current_y = item['y'] if current_y is None else current_y\n",
    "            else:\n",
    "                if current_row:\n",
    "                    parsed_rows.append(self.process_row(current_row, data_type))\n",
    "                current_row = [item]\n",
    "                current_y = item['y']\n",
    "        \n",
    "        # Don't forget the last row\n",
    "        if current_row:\n",
    "            parsed_rows.append(self.process_row(current_row, data_type))\n",
    "        \n",
    "        # Filter out None rows and create DataFrame\n",
    "        valid_rows = [row for row in parsed_rows if row is not None]\n",
    "        \n",
    "        if data_type == \"bond\":\n",
    "            columns = ['date', 'bond_price', 'price_change']\n",
    "        else:  # futures\n",
    "            columns = ['date', 'future_price', 'bid_price']\n",
    "            \n",
    "        df = pd.DataFrame(valid_rows, columns=columns)\n",
    "        return df.dropna(subset=['date'])  # Remove rows without valid dates\n",
    "    \n",
    "    def process_row(self, row_items, data_type):\n",
    "        \"\"\"Process a single row of OCR data\"\"\"\n",
    "        \n",
    "        # Sort items in row by x-coordinate (left to right)\n",
    "        row_items.sort(key=lambda x: x['x'])\n",
    "        \n",
    "        date_val = None\n",
    "        price_val = None\n",
    "        secondary_val = None\n",
    "        \n",
    "        ocr_processor = OCRProcessor()\n",
    "        \n",
    "        for item in row_items:\n",
    "            text = item['text']\n",
    "            \n",
    "            # Try to parse as date\n",
    "            parsed_date = self.parse_date(text)\n",
    "            if parsed_date and not date_val:\n",
    "                date_val = parsed_date\n",
    "                continue\n",
    "            \n",
    "            # Try to parse as financial number\n",
    "            parsed_number = ocr_processor.validate_financial_number(text)\n",
    "            if parsed_number is not None:\n",
    "                if price_val is None:\n",
    "                    price_val = parsed_number\n",
    "                elif secondary_val is None:\n",
    "                    secondary_val = parsed_number\n",
    "        \n",
    "        if date_val and price_val is not None:\n",
    "            return [date_val, price_val, secondary_val]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6be3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressAnalyzer:\n",
    "    \"\"\"Stress scenario analysis following industry best practices\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.business_days_mapping = {3: '3BD', 7: '7BD', 14: '14BD'}\n",
    "    \n",
    "    def calculate_stress(self, df, price_col, days=3):\n",
    "        \"\"\"\n",
    "        Calculate nBD stress using formula:\n",
    "        stress = (price_today / price_today_minus_nBD) - 1\n",
    "        \"\"\"\n",
    "        logger.info(f\"Calculating {days}BD stress for {price_col}\")\n",
    "        \n",
    "        # Ensure data is sorted by date\n",
    "        df_sorted = df.sort_values('date').copy()\n",
    "        df_sorted['date'] = pd.to_datetime(df_sorted['date'])\n",
    "        \n",
    "        # Calculate lagged prices (n business days ago)\n",
    "        df_sorted[f'{price_col}_lag_{days}'] = df_sorted[price_col].shift(days)\n",
    "        \n",
    "        # Calculate stress\n",
    "        stress_col = f'{price_col}_stress_{days}BD'\n",
    "        df_sorted[stress_col] = (df_sorted[price_col] / df_sorted[f'{price_col}_lag_{days}']) - 1\n",
    "        \n",
    "        return df_sorted.dropna(subset=[stress_col])\n",
    "    \n",
    "    def linear_regression_analysis(self, bond_stress, future_stress, days=3):\n",
    "        \"\"\"Linear regression with comprehensive validation\"\"\"\n",
    "        \n",
    "        # Prepare data\n",
    "        X = bond_stress.values.reshape(-1, 1)\n",
    "        y = future_stress.values\n",
    "        \n",
    "        # Fit linear model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        y_pred = model.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        residuals = y - y_pred\n",
    "        mse = np.mean(residuals**2)\n",
    "        \n",
    "        results = {\n",
    "            'days': days,\n",
    "            'alpha': model.intercept_,\n",
    "            'beta': model.coef_[0],\n",
    "            'r_squared': r2,\n",
    "            'mse': mse,\n",
    "            'n_observations': len(y),\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"{days}BD Model: α={results['alpha']:.4f}, β={results['beta']:.4f}, R²={r2:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_stress_plots(self, combined_df, periods=[3, 7, 14]):\n",
    "        \"\"\"Generate comprehensive stress analysis plots\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Bond-Futures Stress Scenario Analysis', fontsize=16)\n",
    "        \n",
    "        colors = ['blue', 'red', 'green']\n",
    "        results_summary = []\n",
    "        \n",
    "        # Plot 1: Multiple period comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        for i, days in enumerate(periods):\n",
    "            if f'bond_price_stress_{days}BD' in combined_df.columns and f'future_price_stress_{days}BD' in combined_df.columns:\n",
    "                bond_stress = combined_df[f'bond_price_stress_{days}BD'].dropna()\n",
    "                future_stress = combined_df[f'future_price_stress_{days}BD'].dropna()\n",
    "                \n",
    "                if len(bond_stress) > 0 and len(future_stress) > 0:\n",
    "                    # Align data\n",
    "                    min_len = min(len(bond_stress), len(future_stress))\n",
    "                    bond_stress = bond_stress.iloc[-min_len:]\n",
    "                    future_stress = future_stress.iloc[-min_len:]\n",
    "                    \n",
    "                    ax1.scatter(bond_stress, future_stress, alpha=0.6, \n",
    "                              color=colors[i], label=f'{days}BD', s=30)\n",
    "                    \n",
    "                    # Fit line\n",
    "                    if len(bond_stress) > 1:\n",
    "                        results = self.linear_regression_analysis(bond_stress, future_stress, days)\n",
    "                        results_summary.append(results)\n",
    "                        \n",
    "                        x_range = np.linspace(bond_stress.min(), bond_stress.max(), 100)\n",
    "                        y_line = results['alpha'] + results['beta'] * x_range\n",
    "                        ax1.plot(x_range, y_line, color=colors[i], linestyle='--', linewidth=2)\n",
    "        \n",
    "        ax1.set_xlabel('Bond Index Stress')\n",
    "        ax1.set_ylabel('Future Stress')\n",
    "        ax1.set_title('Stress Relationships by Time Period')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: 3BD detailed analysis (main focus)\n",
    "        ax2 = axes[0, 1]\n",
    "        if results_summary:\n",
    "            main_result = results_summary[0]  # 3BD typically first\n",
    "            bond_stress = combined_df['bond_price_stress_3BD'].dropna()\n",
    "            future_stress = combined_df['future_price_stress_3BD'].dropna()\n",
    "            \n",
    "            min_len = min(len(bond_stress), len(future_stress))\n",
    "            if min_len > 0:\n",
    "                bond_stress = bond_stress.iloc[-min_len:]\n",
    "                future_stress = future_stress.iloc[-min_len:]\n",
    "                \n",
    "                ax2.scatter(bond_stress, future_stress, alpha=0.7, color='darkblue', s=40)\n",
    "                \n",
    "                x_range = np.linspace(bond_stress.min(), bond_stress.max(), 100)\n",
    "                y_line = main_result['alpha'] + main_result['beta'] * x_range\n",
    "                ax2.plot(x_range, y_line, color='red', linewidth=2, \n",
    "                        label=f'y = {main_result[\"alpha\"]:.4f} + {main_result[\"beta\"]:.4f}x')\n",
    "                \n",
    "                ax2.set_xlabel('Bond Index 3BD Stress')\n",
    "                ax2.set_ylabel('Future 3BD Stress')\n",
    "                ax2.set_title(f'3BD Linear Relationship (R² = {main_result[\"r_squared\"]:.4f})')\n",
    "                ax2.legend()\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Time series of stress values\n",
    "        ax3 = axes[1, 0]\n",
    "        if 'date' in combined_df.columns:\n",
    "            plot_df = combined_df.set_index('date')\n",
    "            for i, days in enumerate(periods):\n",
    "                bond_col = f'bond_price_stress_{days}BD'\n",
    "                future_col = f'future_price_stress_{days}BD'\n",
    "                \n",
    "                if bond_col in plot_df.columns:\n",
    "                    ax3.plot(plot_df.index, plot_df[bond_col], \n",
    "                            color=colors[i], alpha=0.7, label=f'Bond {days}BD')\n",
    "                if future_col in plot_df.columns:\n",
    "                    ax3.plot(plot_df.index, plot_df[future_col], \n",
    "                            color=colors[i], alpha=0.7, linestyle='--', label=f'Future {days}BD')\n",
    "        \n",
    "        ax3.set_xlabel('Date')\n",
    "        ax3.set_ylabel('Stress Value')\n",
    "        ax3.set_title('Time Series of Stress Values')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 4: Model diagnostics\n",
    "        ax4 = axes[1, 1]\n",
    "        if results_summary:\n",
    "            metrics = ['R²', 'Beta', 'Alpha']\n",
    "            period_labels = [f'{r[\"days\"]}BD' for r in results_summary]\n",
    "            \n",
    "            r2_values = [r['r_squared'] for r in results_summary]\n",
    "            beta_values = [r['beta'] for r in results_summary]\n",
    "            alpha_values = [abs(r['alpha']) for r in results_summary]  # Absolute for better visualization\n",
    "            \n",
    "            x = np.arange(len(period_labels))\n",
    "            width = 0.25\n",
    "            \n",
    "            ax4.bar(x - width, r2_values, width, label='R²', alpha=0.7)\n",
    "            ax4.bar(x, beta_values, width, label='Beta', alpha=0.7)\n",
    "            ax4.bar(x + width, alpha_values, width, label='|Alpha|', alpha=0.7)\n",
    "            \n",
    "            ax4.set_xlabel('Time Period')\n",
    "            ax4.set_ylabel('Metric Value')\n",
    "            ax4.set_title('Model Diagnostics Comparison')\n",
    "            ax4.set_xticks(x)\n",
    "            ax4.set_xticklabels(period_labels)\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('stress_analysis_results.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c7652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution pipeline integrating OCR and stress analysis\"\"\"\n",
    "    \n",
    "    logger.info(\"Starting integrated OCR and stress modeling pipeline\")\n",
    "    \n",
    "    # Initialize processors\n",
    "    ocr_processor = OCRProcessor()\n",
    "    data_parser = DataParser()\n",
    "    stress_analyzer = StressAnalyzer()\n",
    "    \n",
    "    # Phase 1: OCR Data Extraction\n",
    "    logger.info(\"=== Phase 1: OCR Data Extraction ===\")\n",
    "    \n",
    "    try:\n",
    "        # Extract bond index data (BEHLTREU)\n",
    "        logger.info(\"Processing BEHLTREU bond index data...\")\n",
    "        bond_data, bond_img = ocr_processor.extract_data_from_image('../Entry_Technical_Test/behltreu.png')\n",
    "        bond_df = data_parser.extract_table_data(bond_data, data_type=\"bond\")\n",
    "        logger.info(f\"Extracted {len(bond_df)} bond price records\")\n",
    "        \n",
    "        # Extract futures data (AHWM5)\n",
    "        logger.info(\"Processing AHWM5 futures data...\")\n",
    "        futures_data, futures_img = ocr_processor.extract_data_from_image('../Entry_Technical_Test/ahwm5.png')\n",
    "        futures_df = data_parser.extract_table_data(futures_data, data_type=\"future\")\n",
    "        logger.info(f\"Extracted {len(futures_df)} futures price records\")\n",
    "        \n",
    "        # Merge datasets on date\n",
    "        combined_df = pd.merge(bond_df[['date', 'bond_price']], \n",
    "                              futures_df[['date', 'future_price']], \n",
    "                              on='date', how='inner')\n",
    "        \n",
    "        logger.info(f\"Combined dataset: {len(combined_df)} overlapping records\")\n",
    "        \n",
    "        # Save raw data\n",
    "        combined_df.to_csv('extracted_data.csv', index=False)\n",
    "        logger.info(\"Raw data saved to extracted_data.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"OCR extraction failed: {e}\")\n",
    "        # Fallback: create sample data for demonstration\n",
    "        logger.warning(\"Creating sample data for demonstration...\")\n",
    "        dates = pd.date_range(start='2025-04-01', end='2025-07-01', freq='B')\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        bond_prices = 300 + np.cumsum(np.random.normal(0, 0.5, len(dates)))\n",
    "        future_prices = bond_prices + np.random.normal(0, 0.2, len(dates))\n",
    "        \n",
    "        combined_df = pd.DataFrame({\n",
    "            'date': dates.strftime('%Y-%m-%d'),\n",
    "            'bond_price': bond_prices,\n",
    "            'future_price': future_prices\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Created {len(combined_df)} sample records\")\n",
    "    \n",
    "    # Phase 2: Stress Scenario Analysis  \n",
    "    logger.info(\"=== Phase 2: Stress Scenario Analysis ===\")\n",
    "    \n",
    "    if len(combined_df) < 15:  # Need minimum data for meaningful analysis\n",
    "        logger.warning(\"Insufficient data for stress analysis\")\n",
    "        return\n",
    "    \n",
    "    # Calculate stress for multiple periods\n",
    "    periods = [3, 7, 14]\n",
    "    for days in periods:\n",
    "        if len(combined_df) > days:\n",
    "            # Calculate bond stress\n",
    "            bond_stress_df = stress_analyzer.calculate_stress(\n",
    "                combined_df, 'bond_price', days=days\n",
    "            )\n",
    "            combined_df = pd.merge(combined_df, \n",
    "                                 bond_stress_df[['date', f'bond_price_stress_{days}BD']], \n",
    "                                 on='date', how='left')\n",
    "            \n",
    "            # Calculate futures stress\n",
    "            future_stress_df = stress_analyzer.calculate_stress(\n",
    "                combined_df, 'future_price', days=days\n",
    "            )\n",
    "            combined_df = pd.merge(combined_df, \n",
    "                                 future_stress_df[['date', f'future_price_stress_{days}BD']], \n",
    "                                 on='date', how='left')\n",
    "    \n",
    "    # Generate comprehensive analysis\n",
    "    results_summary = stress_analyzer.create_stress_plots(combined_df, periods)\n",
    "    \n",
    "    # Save final results\n",
    "    combined_df.to_csv('stress_analysis_data.csv', index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    logger.info(\"=== Analysis Summary ===\")\n",
    "    for result in results_summary:\n",
    "        print(f\"\\n{result['days']}BD Linear Model Results:\")\n",
    "        print(f\"  Formula: Future_Stress = {result['alpha']:.4f} + {result['beta']:.4f} × Bond_Stress\")\n",
    "        print(f\"  R-squared: {result['r_squared']:.4f}\")\n",
    "        print(f\"  Observations: {result['n_observations']}\")\n",
    "    \n",
    "    print(f\"\\nFinal dataset shape: {combined_df.shape}\")\n",
    "    print(\"Files generated:\")\n",
    "    print(\"  - extracted_data.csv (raw OCR data)\")  \n",
    "    print(\"  - stress_analysis_data.csv (with stress calculations)\")\n",
    "    print(\"  - stress_analysis_results.png (comprehensive plots)\")\n",
    "    \n",
    "    logger.info(\"Pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bdda286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 14:19:31,963 - INFO - Starting integrated OCR and stress modeling pipeline\n",
      "2025-07-22 14:19:31,966 - INFO - === Phase 1: OCR Data Extraction ===\n",
      "2025-07-22 14:19:31,969 - INFO - Processing BEHLTREU bond index data...\n",
      "2025-07-22 14:19:31,969 - INFO - Processing ../Entry_Technical_Test/behltreu.png\n",
      "2025-07-22 14:19:33,848 - INFO - Extracted 3 high-confidence text elements\n",
      "2025-07-22 14:19:33,852 - INFO - Extracted 0 bond price records\n",
      "2025-07-22 14:19:33,852 - INFO - Processing AHWM5 futures data...\n",
      "2025-07-22 14:19:33,852 - INFO - Processing ../Entry_Technical_Test/ahwm5.png\n",
      "2025-07-22 14:19:34,770 - INFO - Extracted 11 high-confidence text elements\n",
      "2025-07-22 14:19:34,781 - INFO - Extracted 0 futures price records\n",
      "2025-07-22 14:19:34,781 - INFO - Combined dataset: 0 overlapping records\n",
      "2025-07-22 14:19:34,812 - INFO - Raw data saved to extracted_data.csv\n",
      "2025-07-22 14:19:34,814 - INFO - === Phase 2: Stress Scenario Analysis ===\n",
      "2025-07-22 14:19:34,814 - WARNING - Insufficient data for stress analysis\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
